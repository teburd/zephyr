/*
 * Copyright (c) 2022 Intel Corporation.
 *
 * SPDX-License-Identifier: Apache-2.0
 */

#define DT_DRV_COMPAT intel_cavs_hda_dma

#include <drivers/dma.h>
#include <cavs-mem.h>

#include "dma_cavs_hda.h"



#define LOG_LEVEL CONFIG_DMA_LOG_LEVEL
#include <logging/log.h>
LOG_MODULE_REGISTER(dma_cavs_hda_dma);

/**
 * @brief Intel CAVS HDA DMA (Stream) driver
 *
 * Driver that maps the Zephyr DMA API to the HDA Stream Hardware API which
 * supplies a set of shared fifos (ringbuffers) with read and write positions
 * in the ringbuffer managed and shared by the hardware.
 *
 * The ringbuffer is setup in the DSP memory space but shared with the Host.
 *
 * When a buffer is underrun or overrun, an error condition is set and must be cleared.
 * In ALSA terms these are commonly referred to as xruns.
 *
 * There are 4 types of streams, with a set of each available to be used to communicate
 * to or from the Host or Link (audio hardware device, dmic, i2s, soundwire, etc). Each
 * stream set is uni directional.
 *
 * Set of Streams:
 *
 * host -> dsp
 * dsp -> host
 * link -> dsp
 * dsp -> link
 *
 * Simple single/double/chained buffer transfers much like the DMA API provides in Zephyr are
 * infeasible without stopping the DMA. Instead the shared buffer should be continuously written
 * to or read from, followed by an update to the read or write pointer. In all cases an interrupt
 * can be generated by setting a target address the host or link side of the transfer read/writes to.
 *
 * In this way a watermark can be used to refill the existing ring with more data if desired at
 * a specific time. Given a small enough segment to read/write before getting notified means
 * underruns/overruns are less likely but not impossiblilities.
 *
 * Special care must be taken when starting/stopping the streams. The streams are partially controlled
 * by the DSP but not entirely. Many registers and bitflags are controlled from the host (x86) memory
 * space and cannot be manipulated from the DSP. Careful coordination between the host and the dsp must
 * be done in order to properly configure and avoid locking up the entire machine. A misconfiguration
 * *can* cause the hardware to lock up.
 *
 *
 * Because this "DMA" controller is rather unique in zephyr, a dma_copy_in and dma_copy_out
 * are provided. These functions, depending on the stream direction, allow one to copy into or out of
 * the ringbuffer followed by an update to the read/write pointer of the underlying buffer. They
 * are closer in nature to a ringbuffer
 */

struct cavs_hda_cfg {
	uint32_t base;
	uint32_t channels;
	uint32_t dgcs_start;
};

struct cavs_hda_data {
};


static inline bool dma_cavs_hda_is_enabled(struct device *dev, uint32_t channel)
{
	struct cavs_hda_cfg *dev_cfg = (struct cavs_hda_cfg *)(dev->config);

	return *DGCS(dev_cfg->base, channel) & DGCS_GEN;
}

static inline bool dma_cavs_hda_is_busy(struct device *dev, uint32_t channel)
{
	struct cavs_hda_cfg *dev_cfg = (struct cavs_hda_cfg *)(dev->config);

	return *DGCS(dev_cfg->base, channel) & DGCS_GBUSY;
}

static int dma_cavs_hda_host_out_config(const struct device *dev, uint32_t channel, struct dma_config *config)
{
	__ASSERT(config != NULL, "DMA config should not be NULL");
	__ASSERT(config->channel_direction == MEMORY_TO_HOST, "DMA");
	__ASSERT(config->head_block != NULL, "DMA head block config should not be null");
	__ASSERT(config->head_block->block_size != 0, "DMA block size should not be 0");
	__ASSERT(config->head_block->source_address != 0, "DMA source address should be set");
	__ASSERT(config->head_block->source_address >= L2_SRAM_BASE && config->head_block->source_address < L2_SRAM_BASE + L2_SRAM_SIZE,
		 "DMA block source address should be in cAVS L2 Memory region");

	int ret = 0;

	if (dma_cavs_hda_is_enabled(dev)) {
		LOG_ERR("Error, programming an active channel isn't possible");
		ret = -EINVAL;
		goto exit;
	}

	*DGDDA(dev->config->base, channel) = config->head_block->source_address;
	*DGBS(dev->config->base, channel) = config->head_block->block_size;

exit:
	return ret;
}

static int dma_cavs_hda_host_in_config(const struct device *dev, uint32_t channel, struct dma_config *config)
{
	struct dma_cavs_hda_cfg *dev_cfg = (struct dma_cavs_hda_cfg *)dev->config;

	__ASSERT(config != NULL, "DMA config should not be NULL");
	__ASSERT(config->channel_direction == HOST_TO_MEMORY, "DMA");
	__ASSERT(config->head_block != NULL, "DMA head block config should not be null");
	__ASSERT(config->head_block->block_size != 0, "DMA head block size should not be 0");
	__ASSERT(config->head_block->dest_address != 0, "DMA head block dest_address should be set");
	__ASSERT(config->head_block->dest_address >= L2_SRAM_BASE && config->head_block->dest_address < L2_SRAM_BASE + L2_SRAM_SIZE,
		 "DMA head block dest_address should be in cAVS L2 Memory region");
	__ASSERT(config->dest_data_size != 0, "DMA destination data size should not be 0");
	__ASSERT(config->head_block->block_size % config->dest_data_size == 0, "DMA destination buffer should be integer multiple of data size");

	if (dma_cavs_hda_is_enabled(dev)) {
		LOG_ERR("Error, programming an active channel isn't possible");
		ret = -EINVAL;
		goto exit;
	}

	*DGBBA(dev_cfg->base, channel) = config->head_block->dest_address;
	*DGBS(dev_cfg->base, channel) = config->head_block->block_size;

exit:
	return ret;
}


static int dma_cavs_hda_host_in_start(const struct device *dev, uint32_t channel)
{
	*DGCS(dev->config->base, channel) |= DGCS_GEN | DGCS_FIFORDY;

	return 0;
}

static int dma_cavs_hda_host_out_start(const struct device *dev, uint32_t channel)
{
	*DGCS(dev->config->base, channel) |= DGCS_GEN | DGCS_FIFORDY;
	return 0;
}


static int dma_cavs_hda_stop(const struct device *dev, uint32_t channel)
{
	LOG_DBG("Stopping dma(%s) channel(%d), busy(%d)", dev->name, channel, dma_cavs_hda_is_busy(dev));
	*DGCS(dev->config->base, channel) &= ~(DCGS_FIFORDY);
	LOG_DBG("Waiting for dma(%s) channel(%d) to idle", dev->name, channel);
	while(dma_cavs_hda_is_busy(dev)) {}
	*DGCS(dev->config->base, channel) &= ~(DGCS_GEN);
	LOG_DBG("Stopped dma(%s) channel(%d)", dev->name, channel)
	return 0;
}

static int dma_cavs_hda_init(const struct device *dev)
{
	return 0;
}

static const struct dma_driver_api cavs_hda_dma_driver_api = {
	.config = dma_cavs_hda_config,
	.start = dma_cavs_hda_start,
	.stop = dma_cavs_hda_stop,
};


#define CAVS_HDA_DMA_INIT(inst)						\
									\
	static const struct cavs_hda_dma_cfg cavs_hda_dma##inst##_config = { \
		.base = DT_INST_REG_ADDR(inst),				\
		.channels = DT_INST_PROP(inst, channels),		\
	};								\
									\
	static struct cavs_hda_dma_data cavs_hda_dma##inst##_data = {	\
	};								\
									\
									\
	DEVICE_DT_INST_DEFINE(inst,					\
			      &cavs_hda_dma_init,			\
			      NULL,					\
			      &cavs_hda_dma##inst##_data,		\
			      &cavs_hda_dma##inst##_config, POST_KERNEL, \
			      CONFIG_DMA_INIT_PRIORITY,			\
			      &cavs_hda_dma_driver_api);

/* TODO connect up the BSC interrupt if needed though really... probably not */

DT_INST_FOREACH_STATUS_OKAY(CAVS_HDA_DMA_INIT)
